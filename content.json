{"posts":[{"title":"Meta’s next-generation realtime monitoring and analytics platform","text":"Kraken [1] 是Meta用于取代Scuba的下一代监控分析平台，用于解决Scuba在一致性和可靠性等方面的问题。Kraken一个独特的设计在于使用消息中间件来存储所有的元数据变更，避免分布式环境下进行并发控制的困难。 系统架构 数据存储Kraken主要的数据存储在BLOB上。BLOB是一个类似于Amazon S3的一个分布式对象存储系统。 Kraken中每个数据集会被划分成多个分区。每个数据集的分区数在初始化时为32。之后随着数据的增长，分区数会逐渐增长到最多8192。Kraken的数据分区会进一步被划分到一组shard中。每个分区都唯一对应一个shard。在存储和查询时，Kraken都会以shard为单位进行分配。 Kraken在BLOB上的存储结构如下所示 Kraken数据的根目录为scuba_backup/tree。在这个目录下包含了一组shard目录，每个shard目录对应一个shard。这个shard对应的LogDevice的检查点会被存储在这个shard目录节点上（BLOB是一个对象存储，而不是一个文件系统）。 在shard目录下，保存了属于这个shard的partition数目，每个partition对应一个子目录，里面存储了这个partition下RowBlock文件。每个RowBlock文件中保存了一个或多个RowBlock。每个RowBlock都有用一个64位的随机ID进行唯一标识，里面以列存格式存储了一段时间内的数据记录。一旦生成之后，RowBlock就无法被修改和更新。 元数据存储Kraken的元数据被存储在多个系统中，其中最主要的一个部分使用LogDevice进行存储。 LogDevice是Meta内部自研的一个日志存储系统，从数据模型和访问接口上BookKeeper非常类似。LogDevice允许数据的append写入和顺序消费。每个LogDevice集群可以支持多个log的写入和读取。每个log都有一个唯一的Log ID进行标识，里面包含了一组消息。每个消息可以通过Log ID和序列号（LSN）来唯一标识。 在Kraken中，每个shard都会对应LogDevice中的一个log，里面存储了以下几种消息类型 Data：Data消息里面保存了新导入的RowBlock数据。 Heartbeat：Heartbeat消息没有payload，只是用于检测节点的存活（什么节点？） Compaction：Compaction消息由BCS服务写入，里面保存了已完成的compaction任务信息，包括新生成的RowBlock编号，以及被合并替换的RowBlock编号。 Update：Update消息由Update服务写入，里面保存了被删除或者被替换的RowBlock编号。 Leaf节点Leaf节点是Kraken中提供数据访问的节点。每个leaf节点会负责一个或者多个shard的服务；而一个shard也会被分配给多个leaf节点。 ShardManager负责shard在不同Leaf节点之间的分配。ShardManager会维护shard到leaf节点之间的映射。当查询数据时，root节点可以访问ShardManager来获得查询的shard所在的leaf节点。ShardManager会监控leaf节点的存活和负载情况。当leaf节点故障或者leaf节点之间存在负载不均衡时，ShardManager会在leaf节点之间进行shard的迁移和重新分配。 Leaf节点会消费LogDevice上shard对应的log，根据log中的消息执行相应的操作。 当leaf读取到一个data消息时，会将data消息中的RowBlock加载到内存中 当leaf读取到一个compaction消息时，会从BLOB上读取合并后的RowBlock，并将被合并的RowBlock删除掉 当leaf读取到一个update消息时，会从BLOB上读取新的RowBlock消息，并将被替换的RowBlock删除掉 数据写入Kraken使用Turbine（Meta内部的流计算系统，和Flink类似）来进行数据的读取和写入。Turbine。Kraken会从Scribe（Meta内部的消息中间件，基于LogDevice实现，和Pulsar类似）消费外部写入的日志数据，将这些数据转换成RowBlock的列存格式。 为了保证数据写入的实时性，新生成RowBlock中只会包含数秒的数据。每个新的RowBlock会被赋值一个64位的随机ID用于唯一标识。生成之后，RowBlock的数据和ID都无法被修改。 RowBlock随后会被随机分配到一个partition中。根据partition和shard的对应关系，Turbine会在这个shard对应的log中写入一个data消息。当这个shard对应的leaf节点消费到这个data消息之后，这些新写入的数据就可以反映在查询结果中了。 数据维护在Kraken中，数据的维护包括两部分，一个是数据的备份和合并，另一个则是数据的更新。 数据的备份和合并在Kraken中，数据的备份和合并由Backup and Compaction Service (BCS)服务。和leaf节点类似，每个BCS节点会负责一个或多个shard的备份和合并，由ShardManager进行shard的分配和管理。 每个BCS节点会消费shard对应的log，读取其中的data消息。由于每个shard可能包含多个partition，BCS节点会为每个访问到的partition创建一个队列。当读取到一个data消息时，BCS会将这个data消息放到对应的partition队列上。 BCS节点会对相同数据partition中新写入的RowBlock进行合并。BCS节点会访问这个partition的队列，将队列中的RowBlock合并成一个较大的RowBlock，并将这个RowBlock的数据写入到BLOB上。BCS节点合并数据的频率可以根据配置进行调整。用户可以根据RowBlock的数目进行合并；也可以根据RowBlock的大小进行。 在合并数据的同时，BCS节点也会将LogDevice的检查点写入到BLOB上对应的shard节点中。LogDevice的检查点由log的ID和消费消息的LSN组成，表示了BCS节点当前的合并进度。 当完成数据和元数据的写入之后，BCS节点会在LogDevice中写入一个compaction消息，里面包含了合并后的RowBlock编号和被合并的RowBlock编号。当leaf节点读取到这个compaction消息后，就会将自己维护的RowBlock进行更新和调整。 数据的更新在Kraken中，每个数据都有一定的保留时间。用户可以对整个数据集设置保留时间，也可以对不同列设置不同的保留时间。此外，用户还可以对数据设置降采样策略，将老数据在更大的时间尺度上进行合并或者采样。 Kraken通过Update Service（US）来负责数据的淘汰或者降采样。每个US节点会负责一个或多个shard，扫描BLOB存储上这些shard对应的目录来对数据执行相应的操作。当数据更新完成之后，US也会在LogDevice中写入一个update消息通知leaf节点。 数据查询Kraken的root节点负责接收用户的查询请求。当收到用户查询请求时，root节点会根据数据的partition将查询拆分成多个子查询，每个子查询对应一个partition。之后root节点会查询ShardManager来获得这些partition所在的leaf节点，并将子查询请求发送给这些leaf节点。当这些leaf节点返回子查询结果之后，root节点会对这些子查询结果进行聚合，并将最终的结果返回给用户。 小结在早期Scuba的设计中，由leaf节点同时负责数据的查询的维护。为了避免compaction这些后台服务对查询的影响，Kraken使用了单独的节点来执行这些维护任务。将这些后台任务独立出来的一个挑战就是，如何在分布式环境下对这些不同的数据服务进行并发控制。和其他系统不同，Kraken没有使用带有事务语义的数据存储系统，而是使用了一个写入写出的消息队列，来进行并发控制。 和Procella类似，为了提高数据查询的时效性，Kraken会将新导入的数据直接推送到leaf节点上对外提供服务，而不用等待数据的flush和compaction完成。但通过额外的持久化消息队列来进行消息的传递，显然带来了额外的存储开销以及不必要的数据延迟。 在数据导入上，由于Kraken主要用于指标和日志的监控统计，Kraken只支持数据的append，而不支持数据的upsert。论文也没有对schema升级的支持进行介绍。而在数据查询上，Kraken的大部分请求都是数据聚合，缺少对复杂SQL查询的支持。 参考文献[1] S. Harizopoulos et al. Meta’s next-generation realtime monitoring and analytics platform. In VLDB 2022, vol. 15(12), pp. 3522-3534.","link":"/lakehouses/kraken/"},{"title":"Napa: Powering scalable data warehousing with robust query performance at Google","text":"Napa [1] 是Google内部由于取代Mesa的下一代数据分析系统。相比于Mesa，Napa提供了更加便捷的配置方式来满足用户在数据时效性、查询延迟和资源开销这三方面不同的选择，通过查询时间戳提供了更好的数据一致性；并且支持SQL定义的视图和索引。 Napa据称是在F1 Lightning [2] 的基础上对视图维护和数据查询的能力进行了优化。由于Napa的论文在数据写入和合并等部分上没有太多深入的介绍，这里会参考F1 Lightning论文中对应的内容来推测Napa的实现。不过Napa这篇论文并没有引用F1 Lightning，也没有介绍和F1 Lightning之间的关系。 用户接口和关系数据库类似，Napa将数据组织成一系列的关系表，并将这些表组织成一系列的库。用户可以通过DDL创建库和表，并定义这些表对应的字段信息。此外，用户还可以为每个表创建对应的物化视图和索引。 Napa的数据来源主要是关系数据库，将关系数据库的数据复制到对应的表中。关系数据库的拥有者既可以按照表粒度，也可以按照库粒度来对数据进行复制。Google内部的关系数据库F1 DB和Spanner都支持使用时间戳快照。所有对数据的更新都会被复制到Napa中，并保留原始的提交时间戳。Napa保证在特定时间戳版本上的查询结果，和在关系数据库中相同时间戳版本上的查询结果，是完全一致的。 Napa使用F1 Query来进行数据查询，视图创建和视图维护等。F1 Query同时支持流处理和批处理，因此我们可以使用同一个系统同时进行交互式查询和大规模数据的处理。 为了保证数据的查询性能，Napa会对复制的数据进行一系列的加工，包括数据转换、数据合并和视图维护等。因此从事务在关系数据库中被提交到这些事务的更新反映到最终的查询结果中，会有一定的数据延迟。Napa使用查询时间戳（Query Timestamp）来表示当前系统数据导入和加工的进度。如果一个表的查询时间戳为$X$，那么意味着所有在时间$X$之前导入到Napa的数据都已经可以被查询，而所有在$X$之后导入的数据则不会反映在查询结果中。此时，这个表的数据延迟即为$\\text{Now}() - X$，其中$\\text{Now}()$表示当前实际的时钟时间。当在时间$Y - X$中导入的数据已经加工优化完成之后，这个表的查询时间戳就可以从$X$更新为$Y$。而对于数据库而言，一个数据库的查询时间戳即为这个数据库中所有表的查询时间戳的最小值。Napa论文中没有说明这里的查询时间戳是时钟时间还是事件时间。如果为了保证Napa和关系数据库在查询语义上的一致性，那么这里的查询时间戳需要为事件时间。 用户可以为Napa中的数据设置一定的保留时间。一个表的保留时间戳即为这个表保留的最老的版本。保留时间戳和查询时间戳之间的时间范围称为查询窗口，用户可以在这个窗口内对表的任意快照进行查询。根据Lightning论文的介绍，谷歌内部的查询窗口的大小通常为10个小时。 数据的加工虽然会为下游的查询带来更好的性能，但在相同的资源开销下也意味着会有更大的数据延迟。Napa允许用户根据预期的查询性能、数据延迟和成本来进行配置。这些配置之后可以转化成内部的系统配置，如物化视图的数目、处理任务的配额、可以保留的Delta数目等。如果用户希望以较低的成本获得较好的查询性能，Napa会优先使用较少的机器资源来构建充分的视图并进行维护，但此时用户就需要忍受较大的数据延迟。 系统架构 数据存储Napa中的表、索引和视图在物理上是一致的。这些数据会根据主键划分成一组分区（partition），而每个分区在本质上都是一个LSM树。我们将这个LSM树的每部分称为一个Delta，里面保存了一段连续时间内对这个分区数据的更新。 Delta中的更新记录被称为部分行版本（Partial Row Version）。每个部分行版本都由对应行的主键以及一个时间戳唯一标识。这个时间戳即为这个更新在关系数据库中对应事务提交的时间。此外，每个部分行版本还包含了这行的内容以及对这行进行的更新动作。 Napa的数据都被存储在Colossus上。在磁盘上，Delta文件按照读优化的列存格式进行存储。Napa构建一个抽象的公共接口来支持多种不同的存储格式。在其中最常用的一种数据格式中，每个Delta文件被分为数据和索引两部分。其中数据分布使用PAX格式来存储部分行版本，而索引部分则保存了一个稀疏的B树所有，用来记录每个主键在PAX中对应row bundle的位置。 当一个表初始化时，Napa会运行一个离线任务来生成这个表的划分策略，并从关系数据库中全量拉取读取每个分区对应的数据来创建一个初始的Delta。Napa会定期对已有的数据进行重新划分来保障负载均衡。Napa重新划分数据的过程和HBase十分类似，不会对数据进行重新读写，而只会对元数据进行修改。 元数据存储数据存储的状态和其他需要事务语义的元数据都被存储在Spanner这样的数据库中。 Napa使用了一个两层结构来存储数据的schema信息 第一层是逻辑schema，包含了protobuf和GoogleSQL结构等复杂数据类型，以及其他一些能够在逻辑上映射到整型数的类型，如日期和枚举类型等。 第二层是物理schema。对于每个逻辑schema，Napa会生成一个或多个物理schema。这些物理schema中只会报客户一些基础的数据类型，如整型数、浮点数和字符串等。 逻辑schema和物理schema会通过逻辑映射连接。这个映射指定了如何将逻辑行转换成物理行，以及如何将物理行转换成逻辑行。通过schema映射我们可以为同一个逻辑数据提供不同的物理存储格式。例如在存储Protobuf类型时，我们可以将数据存储为一个序列化的字节流，也可以将其字段分解为单独的列。前者更适合读取大部分或者所有字段的查询，而后者更适合只读取几个字段的查询。在不同的场景下，我们可以通过schema映射选择更合适的方案。schema映射另一个优势是，可以帮助我们更高效地支持那些只需要修改元数据的schema升级。 一些schema升级可以只需要修改元数据，而不需要修改之前使用旧schema写入的Delta文件。例如我们为表添加新列的时候，我们可以在读取这些旧Delta文件时为新的列生成默认值借。当遇到这些只需要修改元数据的schema升级时，Napa会创建一个新的逻辑schema。在schema变更之后的Delta文件会使用新的物理schema写入数据。而对于旧的Delta文件，Napa会分析老的逻辑schema和新的逻辑schema之间的区别，创建一个schema变更的逻辑映射。这个逻辑映射会确定Napa如果将之前旧数据如何转换成新的逻辑schema。 随着时间的推移，一个表中可能存在许多schema升级，因而也会保存大量的schema变动的逻辑映射。在读取时执行schema的变更会带来一定的性能开销。为了减少这部分开销，Napa定期会在compaction过程中对旧数据进行转换，使用新的schema来保存。 而如果schema升级需要修改数据，而无法只修改元数据的话，那么Napa会调用后台的任务来对旧数据进行转换和改写。 Delta ServerNapa中数据的写入、合并和查询服务都由DeltaServer提供支持。每个Server会负责一个或者多个partition，而每个partition的数据会写入到多个server上并对外提供查询服务。但在任意时刻，只有一个server会将partition写入的新数据flush到磁盘上。 数据导入当关系数据库中的变更被导入时，其对应的部分行版本会写被写入到一个内存中的B树。和C-Store或者$C_0$ LSM树这些写优化的存储类似，这种方式允许以读取效率为代价获取更好的更新效率。在Lightning论文中提到，这些数据一旦被写入到内存中，就可以对外提供服务；而在Napa论文中，这些写入内存的数据无法立即对外查询，而需要在进行合并之后才可以对外提供服务。 当内存中Delta大小超过限制，或者Server内存压力太大时，Napa会将这些内存中的Delta写到磁盘上。此时我们会将行存的内存数据转成更适合查询的列存格式。如果在转换时，仍然有查询在访问内存数据，那么这些内存数据仍会被保留直到这些查询执行完成。当内存数据被完全写到磁盘之后，之后的查询就会从磁盘上读取这些数据。 在导入时，一份数据会被写入到多个Server上。这些Server会同时对外提供查询。但这些Server中只有一个会将内存中的Delta转成列存格式写到磁盘上。当这个Server将数据写入磁盘之后，会通知拥有这份数据的其他Server更新他们的数据。 当Server中的内存数据丢失时，Server会从上游的CDC回放这些数据来重建。为了避免在故障恢复之后需要回放太多的数据，Server也会定期的将内存中的数据备份到磁盘上。这些数据的备份和写入是不同的。在备份时，我们不会进行格式的转化，而是直接将内存中的格式写入到磁盘上。 数据维护数据的维护包括了两部分，一部分是在对表的不同Delta进行合并；第二个部分是基于输入表的更新来对索引和视图表进行维护。Napa的控制台会调度数据合并和视图维护的任务来保证一个表的delta数目符合配置的要求。 数据合并由于每个Delta文件内部的记录都是排序的，因此compaction的本质上就是合并排序。 Napa内部的compaction分为四类 Active compaction：对内存中的Delta进行compaction Minor compaction：对磁盘上较新的较小的Delta进行compaction Major compaction：对磁盘上较老的更大的Delta进行compaction Base compaction：生成对应时间戳的一个完整的数据快照 为了能够跟上Delta写入的速度，Napa设计了一个基于大小的compaction策略。Napa使用了两种不同的compaction任务类型，即Minor compaction和Major compaction。Minor compaction负责压缩小的和更新的delta，而major compaction负责合并大的和旧的delta。当Napa为compaction选择合并的delta时，会使用参与compaction的delta的大小作为标准，从一个较小的阈值开始，指数级的增加这个阈值，知道可以找到两个或多个符合要求的delta。这可以使Napa可以快速减少小delta的数量，同时避免在连续的compaction任务中重复重写大量数据。 在上面四种compaction任务中，只有active compaction是在Server上完成，而其他三类compaction都在专门的worker上执行。这样这些compaction任务就不会与Server上的读取操作和其他关键任务争抢资源。当compaction任务完成之后，Server会异步加载最新的Delta，替换掉被合并的Delta。 索引和视图的维护在Napa中，Server可以通过订阅Changepump这样的CDC服务来获得基础表的更新。而索引和视图这些派生表的更新，则需要订阅维护这些输入表的Server。每当基础表发生更改时，维护这些基础表的Server就会为每个派生表计算和发送对应的更新。 由于派生表的主键和基础表的主键并不一致，一个基础表分区的更新可能会导致多个派生表分区的更新，而一个派生表分区可能需要订阅多个基础表分区。为了基础表和派生表之间的shuffle问题，Napa使用BigTable来作为shuffle的存储。维护基础表的Server会将派生表的更新写入到BigTable中。这些更新在BigTable中会按照对应主键的顺序进行排列。维护派生表的Server则会扫描BigTable中对应的主键分区来读取属于自己的更新。 派生表的维护中也会出现数据倾斜的问题。当基础表中大部分的更新在转换之后，可能只会导致派生表一小部分的更新。此时，维护这些派生表分区的Server就会由于负载过大而导致处理性能不足。Napa会随时监控系统中的数据倾斜并重新划分数据。此外，Napa在查询时也会通过慢节点规避的方式来避免查询性能受到影响。 在索引和视图的维护中，一个有效的优化就是尽量保护数据已有的排序和分区特性，避免在维护过程中重新计算。例如，如果基础表已经是按照列(A, B, C)进行排序，而如果派生表按照(A, B)拍序，那么我们就可以将基础表按照(A, B)进行分组，在分组内进行派生表的计算。 数据查询数据合并Napa在查询时需要根据用户指定的时间戳读取对应的版本。但这些版本可能分散在多个Delta文件中，因此在读取数据时需要将多个Delta文件进行合并来获得完整的数据。 Napa在查询时进行的数据合并和compaction是十分类似的，但不同的是合并相比于compaction读取的文件会更少一点。我们在枚举需要参与合并的Delta文件时，会通过主键上的谓词对Delta文件进行过滤，忽略那些与谓词没有匹配的Delta文件。 查询优化为了提供查询的稳定性，Napa做了大量的工程实现上的优化。这些工作主要思想都是提高关键路径上的IO效率。 在任何可能的情况下，F1会优先使用视图表而非基础表来执行查询 当F1的节点从Napa中读取数据时，会尽量将过滤和聚合下推到Napa中。Napa维护了一个稀疏的B树索引，可以利用这些索引快速确定和过滤筛选查询所需的数据所在的Server。 一般的数据分析系统会按照主键范围来对查询进行拆分。如果我们有N个子查询，M个Delta文件，那么每个子查询都要读取这M个Delta文件。Napa为了减少不必要的IO，会让每个DeltaServer处理一个Delta文件，这样查询执行时所读取的IO数目就会大大减少。 Napa对元数据进行了缓存，确保在查询执行过程中所有的元数据都可以直接从内存中访问，而不会从持久化存储上读取。 Napa也使用了一个透明的分布式缓存层来对数据进行了缓存。这个数据缓存是读穿透的，即所有的查询会先从缓存读取数据。当读取不到数据时，Napa会从Colossus加载数据到缓存之后，再从缓存返回数据。此外，Napa也会运行后台和在线的预加载来进一步减少在查询执行时等待时间。 Napa会监控执行过程中的慢节点，通过备份的方式规避慢节点导致的问题。 小结从整体架构上看，Napa有点类似于一个高级的支持SQL查询的HBase。但Napa最大的亮点在于通过简单的配置来满足用户在数据时效性、查询延迟和成本上的选择。这种配置方式具有极大的灵活度，能够为不同的数据分析场景提供统一的解决方案。 满足这个目标的一个重要前提是对数据的加工和查询能够提供稳定可预测的运行。但在分布式环境下对实时更新的数据提供这样的保障是十分具有挑战的。Napa在工程实现上做了许多工作来应付这些挑战，包括解决数据导入和维护过程中的数据倾斜、提高查询稳定性等。 参考文献[1] A. Agiwal et al. Napa: Powering scalable data warehousing with robust query performance at Google. In VLDB 2021, vol. 14(12), pp. 2986-2997. [2] J. Yang et al. F1 Lightning: HTAP as a Service. In VLDB 2020, vol. 13(12), pp. 3313-3325.","link":"/lakehouses/napa/"},{"title":"Procella: Unifying serving and analytical data at Youtube","text":"Procella是Youtube新一代的SQL处理引擎 [1]，其能够支持批式和实时的数据导入，并为不同的分析场景提供统一和高效的数据查询服务。 Youtube内部的数据分析场景主要分为报表和大盘、内嵌统计、时序监控和Ad-hoc查询等四类。这四类查询在数据量、查询复杂度和查询吞吐上具有完全不同的特点。例如报表和大盘需要处理的数据量较大，查询更加复杂，但对数据的新鲜度的要求较低；而内嵌统计和时序监控则要求最高的数据新鲜度，其需要处理不断变化的数据，并支持每秒数百万次的查询。 在过去，这四类数据分析场景分别由不同的系统来支持，例如Adhoc分析和内部小数据的报表需求由Dremel来支持；面向外部的大数据报表由Mesa和Bigtable来支持；监控由Monarch支持；而嵌入统计由Vitess来支持。但对不同的场景使用不同的系统来支持，存在着以下的挑战 数据需要在不同的系统之间流转，带来了很多不必要的计算和存储资源的浪费。 在不同系统中也很难维护数据的一致性。 由于这些系统的API和语义并不完全相同，因此对于开发人员来说，使用这些不同系统的学习成本较高，开发效率也较低。 为了解决上述问题，Youtube研发了Procella，来为不同的数据分析场景提供统一的数据导入和查询服务。 用户接口和数据库类似，Procella中的数据被组织成一系列的表。这些表的数据会被保存在多个文件中，其中每个文件被称为一个tablet或一个partition。Procella支持多层的分区（partitioning）和聚簇（clustering）。一般事实表会按照日期来分区，而在分区内数据会按照多个维度进行聚簇。而维度表则一般会按照维度进行划分和排序。 Procella通过标准的DDL语句来对表进行创建、删除和修改。用户可以在表的定义中指定和修改列的名称和数据类型、表的划分和排序方式、约束、和数据导入的方式。对于实时表，用户还可以指定数据的降采样（down-sampling）和过期方式等。而在对数据进行查询时，Procella支持几乎全部的SQL特性，包括多级连接、集合操作和嵌套查询等。 系统架构 数据存储Procella使用Google内部的分布式文件系统Colossus来存储数据。 Procella支持多种数据存储格式。早期Procella使用Capacitor来作为主要的数据存储格式，但Capacitor主要是针对Adhoc分析场景进行设计，其能够支持高效的数据扫描，但缺少对数据索引的支持。为了更好的支持内嵌统计和监控等场景，Procella设计了Artus格式，其能够同时支持高效的数据扫描和检索。 Artus没有使用LZW或ZSTD这样通用的压缩算法来对数据进行编码。相反的，Artus使用了一个自适应编码方式。在编码时，Arthus会扫描数据多遍。在第一遍时，会采集数据的一些信息，包括数据的基数、最大值、最小值和排列顺序等。之后Artus会利用这些信息来选择数据的最优编码方式。Artus相比于ZSTD这类通用算法能够获得高达2倍的压缩率。 Artus对嵌套和重复的字段类型也是用了新的编码方式来提高检索效率。 另外，Artus的一个最大的优点是，其可以在不解压数据的情况下执行按主键检索等很多操作。这可以显著的减少在数据查询时的IO开销，提高执行效率。 非常遗憾的是，Procella的论文并没有给出Artus的实现细节。 元数据存储Procella使用BigTable和Spanner来存储表字段信息等元数据信息。 除了表的字段信息，元数据信息还包括了一些用户提高查询效率的统计信息和辅助结构，如数据分区的zonemap，bitmap，倒排索引和bloom filter等。这些元数据一些是在导入或者维护过程中从数据文件的头部中抽取出来的。 计算节点Procella中包含了多种不同角色的计算节点，包括 Root Server（RS）：根节点，用来接收用户查询，对用户查询进行解析，使用MDS提供的元数据信息来对用户查询进行优化，并负责用户查询的调度和执行。 Metadata Server（MDS）：元数据节点，用于支持元数据的查询。 Data Server（DS）：负责执行数据的检索和查询。每个DS会负责一部分数据；而为了提高可靠性，任意一份数据都可能由多个DS提供服务。 Ingestion Server：负责将用户实时导入的数据写入到Procella中。 Compaction Server：负责将导入的数据进行整理合并，形成更适合于查询的文件。 Registration Server：负责对系统中新生成的文件进行校验和登记。这些文件可能是批式导入的文件，也可能是Compaction生成的文件。 所有这些计算节点都运行在Google内部的资源管理系统Borg上。 数据导入数据的导入分为离线导入和实时导入两种方式。 离线导入在离线导入时，用户只需要将需要导入的文件通过RegistrationServer登记到系统中即可。RegistrationServer会对文件的字段信息等进行校验，并将文件的元数据信息（如bloom filter）读取并写入到元数据存储中。 在导入过程中，Procella会尽量扫描文件中的数据。RegistrationServer只会读取文件的头来读取必要的元数据信息。但如果用户导入的文件中缺少必要的元数据信息，那么Procella会使用DS来扫描文件并生成所需的元数据信息。 实时导入在实时导入时，用户首先通过RPC或者PubSub接口将数据交给IngestionServer。 IngestionServer在收到数据之后，会将数据按照写入的表的格式进行转换，并将数据追加写到Colossus上的一个WAL日志中。这些WAL日志文件在之后会被compact成更利于查询的列存格式。 除此之外，IngestionServer还会通过双写将转换后的数据立即发送到对应的DataServer上。这些数据会被临时保存在DataServer的内存中，并立即可以对外提供查询。在正常的流程中，DataServer需要在执行查询时才会从Colossus中读取查询所需的数据。通过将新数据写入Colossus的同时就立即推送到DataServer上，Procella可以显著的提高新数据的时效性，降低查询延迟。这对于嵌入统计和监控等场景来说，是尤为关键的。 但这个时效性的提升可能会导致数据的不一致。假设用户先从DataServer的内存中查询到了新写入的数据。当DataServer出现故障丢失了内存中的这些数据，如果Colossus的写入还没有完成的话，那么用户在第二次查询时就无法访问到这些丢失的数据，产生和第一次查询时不一致的结果。为了缓解这个问题，Procella会将DataServer内存中缓存的新数据定期备份到Colossus上。这样在DataServer从故障中恢复时，丢失的新数据是有限的。但由于这个备份并不是实时的，因此备份只可以减少丢失的数据量，而无法根本避免一致性问题。如果用户对一致性要求比较高，那么就需要新数据的即时推送，要求DataServer在查询时只可以访问Colossus上已经持久化的数据。 写入WAL日志文件的数据何时可以被查询，在论文中没有介绍。这些数据可能在写入文件之后、文件关闭之后或者文件compact成列存格式之后这三种不同的情况下可以被查询。个人感觉，这些文件的数据在Compact完成之后才可以被查询。 数据维护CompactionServer会定期的对实时导入产生的WAL日志文件进行compact，生成更利于查询的列存格式的文件。在compact过程中，CompactionServer也可以执行用户自定义的合并逻辑，来对数据进行过滤或者聚合。 数据查询用户将SQL发送到RootServer来进行数据查询。RS会对SQL进解析、重写和优化，来生成执行计划。之后RS会根据数据的划分将执行计划进行拆分成物理的执行任务，将这些任务发送到对应的DS上，由这些DS来执行。当这些DS执行完成之后，由RS将最终的结果返回给用户。 在执行过程中，DS之间通过Stubby来进行shuffle。此外，如果执行计划使用Lookup的方式来进行连接，那么一个DS还可能通过RPC来访问另一个DS来按照主键检索数据。 查询优化Procella使用了动态查询优化技术来对查询进行优化。在编译阶段，优化器只会使用一个基于规则的优化器来执行一些较为明确的优化，例如谓词下推，子查询解关联等。在运行阶段，Procella会在执行过程中收集上一阶段结果的统计信息，并根据这些信息来对执行计划进行优化和调整。 为了收集运行时的统计信息，Procella当前会在每个shuffle操作之前添加一个额外的collection sites算子。由于shuffle时会对所有的数据进行遍历，collection sites算子正好可以在此时收集必要的统计信息。 基于这些收集的统计信息，Procella可以对聚合，连接和排序等算子的执行计划进行调整和优化。例如对于连接算子，Procella可以选择不同的连接方式，如广播连接，还是hash连接。 任务执行Procella的查询执行引擎，称为Superluminal，可以认为是Google之前开源的向量化引擎Supersonic的升级版。 现在很多的OLAP引擎会通过LLVM将执行计划编译成本地代码，从而提高查询的执行性能。但这些本地代码的编译本身也会带来一定的时间开销，在内嵌统计和监控这些查询吞吐很高而查询时间又很短的场景中，代码编译带来的收益就很小了。为了能够同时支持不同的数据分析场景，Superluminal使用了大量的C++模板来生成代码。这种方式可以认为是解释执行和本地执行的一种折中，一方面可以减少解释执行带来的虚函数开销，一方面又可以减少本地代码生成的编译开销。 Superluminal会充分使用向量化技术来提高数据并行度，并将数据块的大小进行调整来适合L1 Cache，提高代码执行时的Cache访问效率，尽量减少执行过程中产生的中间结果。 由于Artus格式可以在不解压数据的情况下执行很多数据操作，Superluminal会将过滤和聚合等数据操作尽量下推到Artus中执行，进一步提高数据访问效率。 任务调度在查询执行过程中，Procella也会出现长尾问题导致查询延迟变高。为了避免长尾问题，RS会监控DS执行请求的响应时间。如果一个请求的响应时间比中位数要高，那么RS会额外发送这个请求到其他DS上。 此外，RS会为每个请求附上不同的优先级。一般来说，更小的查询的优化级会更高。而DS会为不同优先级的请求维护不同的线程池。这样，更小的查询能够得到更快的响应；系统不会由于执行线程被大查询打满而导致系统整体的查询延迟和吞吐下降。 小结Procella的一个亮点在于导入阶段支持流批一体的导入，这对于构建一个Single Source of Truth的数据湖是尤为关键的。Procella在论文中提到了它可以支持物化视图，但也没有详细介绍物化视图是如何更新维护的。 Procella的另一个亮点是对于不同数据分析场景的支持。特别的，Procella花费了很多精力来支持内嵌统计和监控这类查询吞吐高，数据延迟和查询延迟低的查询场景。比如Procella增加了IngestionServer到DataServer的旁路来降低新数据的延迟，使用代码模板而非本地代码来避免编译开销等等。 Procella中使用Artus格式来存储数据，可以支持在压缩数据上直接进行数据的过滤和检索，也是一个非常有意思的工作。但这部分在论文中没有介绍具体的实现细节，比较遗憾。 另外，Procella的论文中没有对可靠性的细节进行详细的介绍。Procella依赖Borg来对计算节点进行资源管理，但论文中没有介绍在扩缩容过程中，DS之间的数据划分和备份是如何动态调整的。 参考文献[1] B Chattopadhyay et al. Procella: unifying serving and analytical data at Youtube. In VLDB 2020, vol. 12(12), pp. 2022-2034.","link":"/lakehouses/procella/"},{"title":"物化视图维护的代数方法","text":"为了保证与数据源的一致性，当数据源发生变化时，物化视图需要进行及时的更新。很多时候，数据源的变化相比于整体而言是较小的。此时使用增量更新的方式来对物化视图进行维护会更加高效。本文主要介绍维护物化视图的代数方法。这些方法可能在某些算子上无法提供最高效的维护方法，但在语义上比较直观。 研究历史对物化视图维护的研究最早可追溯到1980年代。这些早期的工作都局限在特定的数据库模型上。[1] 对函数式关联数据模型 (functional association data model) 上的视图维护方法进行了研究。而 [2] 只支持无环数据库 (acyclic database) 上的视图。这些视图先将数据表中所有关系表进行自然连接，之后进行映射；无法支持选择操作，也无法对部分表进行连接。 [3] 是第一个对一般物化视图的维护进行研究的工作，他们的方法可以对包含选择、映射和连接等操作在内的视图进行维护。[4] 则进一步提出使用代数方法 (algebraic method) 来描述物化视图维护的方法。在代数方法中，输入表$R$的更新被描述为一对增量表：$\\nabla R$和$\\Delta R$。其中$\\nabla R$表示$R$中被删除的记录，而$\\Delta R$表示$R$中新插入的记录。我们使用一组等式来描述这些变化是如何在算子之间传播的。在 [4] 中，作者提供了集合代数 (set algebraic) 上选择、映射、笛卡尔积、并、差、交和内连接等算子的变化传播方程 (change propagation equation)。[5] 则给出了包代数 (bag algebraic) 上相关算子的变化传播方程。 [6] 为包含外连接的视图提供了维护方法，但他们的方法并不是基于代数形式的。[7] 给出了描述维护半连接和外连接视图的代数方法。[8] 给出了基于change table方法对外连接视图进行更新的方法，但他们的方法显然是错误的。 相较于其他算子，聚合算子的变化传播很难通过代数形式进行描述。首先，聚合算子本身的代数描述就比困难。其次，部分聚合操作（如 median）并不满足分配律 (distributive property)，因此无法很难描述输出变化和输入变化之间的关系。 [5] 给出了聚合算子的变化传播方程，但他们的聚合算子无法支持分组语句 (group-by)，并且只能作为视图中最后一个算子。[8] 通过通用映射 (general projection) 来对聚合操作进行描述，给出了一般情况下可分配的聚合算子的变化传播方程。除此之外，其他在维护聚合视图上的工作 [10, 11]，都只描述了具体的过程，而没有给出形式化描述。 在维护视图的代数方法中，如果我们向后传播的插入和删除中存在重叠的记录，那么显然会导致后面的增量更新存在不必要的冗余计算。我们希望向下游传播的变化是最小化的，即$\\Delta R \\cap \\nabla R = \\emptyset$。[4] 虽然给出了常见算子的变化传播方法并号称这些方法满足最小化条件，但实际并非如此。[12] 指出了 [4] 中的错误，并给出了一个通用的构建最小化结果变化的方法。 虽然代数方法可以用于解决一般情况下的视图更新问题，但在实际中我们的视图通常会多个嵌套的算子。此时使用代数方法去逐个算子逐个输入的去计算视图的变化效率会非常低。此时，我们常常需要一些更加高效但没有那么纯粹 (pure) 的方法来计算视图的更新 [9]。 视图更新的代数方法选择 (Select)选择算子的变化传播方程如下 $$ \\sigma_p(R \\cup \\Delta R) = \\sigma_p(R) + \\sigma_p(\\Delta R)$$ $$\\sigma_p(R - \\nabla R) = \\sigma_p(R) - \\sigma_p(\\nabla R)$$ 映射 (Project)映射算子的变化传播方程如下 $$\\pi_A(R \\cup \\Delta R) = \\pi_A(R) \\cup \\pi_A(\\Delta R)$$ $$\\pi_A(R - \\nabla R) = \\pi_A(R) - \\pi_A(\\nabla R)$$ 并 (Union)集合代数和包代数下并操作有着不同的语义。我们使用UNION和UNION ALL来区分这两种不同的操作。 UNION ALL我们使用$R \\cup S$来表示表$R$和$S$在包语义下的并操作。如果一个记录$t$在$R$中出现了$n$次，在$S$中出现了$m$次。如果$n &gt; 0$或者$m&gt;0$，那么$t \\ in R \\cup S$，并且在$R\\cup S$中出现$n + m$次。 UNION ALL的变化传播方程如下 $$(R - \\nabla R) \\cup S = (R \\cup S) - \\nabla R$$ $$(R \\cup \\Delta R) \\cup S = (R \\cup S) \\cup \\Delta R$$ UNION我们使用$R\\sqcup S$表示表$R$和$S$在集合语义下的并操作。如果一个记录$t$在$R$出现了或者在$S$中出现了，那么$t$也会出现在$R \\sqcup S$中，并且只出现一次。 当$R$中某个记录$r$被删除时，对于$R \\sqcup S$可能存在以下两种情况 如果$r$在$R - \\nabla R$或者$S$中出现了，那么$r$仍然会在最终的结果中出现。$r$的删除并不会对最终的结果产生任何影响。 如果$r$既没有出现在$R - \\nabla R$中，也没有出现在$S$中，那么从$R$中删除$r$之后，$r$也会从最终的结果中被删除。我们使用$\\nabla R \\ominus ((R - \\nabla R) \\sqcup S)$ 来表示$\\nabla R$中没有出现在$R - \\nabla R$和$S$中的记录。 根据上面的讨论可知： $$ (R - \\nabla R) \\sqcup S = (R \\sqcup S) - (\\nabla R \\ominus ((R - \\nabla R) \\sqcup S))$$ 当$R$中添加某个记录$r$时，对于$R \\sqcup S$可能存在以下两种情况 如果$r$已经在$R$或者$S$中出现了，那么$r$已经在最终的结果中出现了。插入$r$并不会对最终的结果产生任何影响。 如果$r$既没有出现在$R$中，也没有出现在$S$中，那么$r$就需要添加到最终的结果中。我们使用$\\Delta R \\ominus (R \\sqcup S)$来表示$\\Delta R$中既没有出现在$R$也没有出现在$S$中的记录。 根据上面的讨论可知 $$(R \\cup \\Delta R) \\sqcup S = (R \\sqcup S) \\cup (\\Delta R \\ominus (R \\sqcup S))$$ 交 (Intersect)和并操作一样，交操作需要区分集合语义和包语义。我们使用INTERSECT ALL表示包语义下的并操作，INTERSECT表示集合语义下的并操作。 INTERSECT ALL我们使用$R \\cap S$表示表$R$和$S$在包语义下的交操作。如果一个记录$t$在$R$中出现了$n$次，在$S$中出现了$m$次，并且$n &gt; 0, m &gt; 0$，那么$t \\in R \\cap S$，并在$R \\cap S$中出现$\\min(n, m)$次。 当$R$中删除一个记录$r$时 如果$n &gt; m$，那么在删除掉$r$不会对最终的结果产生影响。 如果$n \\le m$，那么在删除掉$r$之后，应该在最终的结果中减少一次$r$的出现。 根据上面的讨论可知 $$ (R - \\nabla R) \\cap S = (R \\cap S) - (\\nabla R - (R - S)) $$ 当$R$中插入一个记录$r$时 如果$n \\ge m$，那么在添加$r$时不会对最终的结果产生影响。 如果$n &lt; m$，那么在添加$r$后，应该在最终的结果中增加一次$r$的出现。 根据上面的讨论可知 $$ (R \\cup \\Delta R) \\cap S = (R \\cap S) \\cup (\\Delta R \\cap (S - R)) $$ INTERSECT我们使用$R \\sqcap S$表示表$R$和$S$在集合语义下的交操作。如果一个记录$t$在$R$中出现了，在$S$中也出现了，那么$t \\in R \\sqcap S$，并在$R \\sqcap S$中出现一次。 参考UNION的讨论方式，可得INTERSECT的变化传播方程为 $$(R - \\nabla R) \\sqcap S = (R \\sqcap S) - (\\nabla R \\sqcap (S \\ominus (R - \\nabla R)))$$ $$(R \\cup \\Delta R) \\sqcap S = (R \\sqcap S) \\cup (\\Delta R \\sqcap (S \\ominus R)))$$ 差 (Minus)和并操作一样，差操作需要区分集合语义和包语义。我们使用MINUS ALL表示包语义下的差操作，MINUS表示集合语义下的差操作。 MINUS ALLMINUS ALL按照包语义执行差操作。我们使用$R - S$表示表$R$和$S$在包语义下的差操作。如果一个记录$t$在$R$中出现了$n$次，在$S$中出现了$m$次，并且$n &gt; m$，那么$t \\in R - S$，并且在$R - S$中出现$n - m$次。 MINUS ALL的变化传播方程如下 $$(R - \\nabla R) - S = (R - S) - \\nabla R$$ $$(R \\cup \\Delta R) - S = (R - S) \\cup \\Delta R$$ MINUSMINUS按照集合语义执行差操作。我们使用$R \\ominus S$表示表$R$和$S$在集合语义下的差操作。如果一个记录$t$在$R$中出现了，但在$S$中没有出现，那么$t \\in R \\ominus S$，并且在$R \\ominus S$只出现一次。 当我们从$R$中删除一个记录$r$时 如果$r$没有在$S$中出现，那么$r$应该会出现在原来的结果中。 如果$r$也没有在$R - \\nabla R$中出现，那么将$r$从$R$中删除之后，$r$就需要从最终的结果中删除掉。 如果$r$出现在$R - \\nabla R$中，那么将$r$从$R$中删除之后，并不会对最终的结果产生任何影响。 如果$r$出现在$S$中，那么$r$本来就不存在于原来的结果中。删除$r$并不会对最终的结果产生任何影响。 根据上面的讨论可知，当$r$既没有出现在$S$中也没有出现在$R - \\nabla R$中时，删除$r$会导致$r$从最终的结果中删除。因此 $$(R - \\nabla R) \\ominus S = (R \\ominus S) - (\\nabla R \\ominus ((R - \\nabla R) \\sqcup S))$$ 当我们向$R$中插入一个新记录$r$时 如果$r$已经出现在$S$中了，那么$r$不会出现在原来的结果中，插入$r$也不会导致最终结果的变化。 如果$r$没有在$S$中出现 如果$r$已经出现在$R$中了，那么插入$r$也不会导致最终结果的变化。 如果$r$没有出现在$R$中，那么插入$r$后$r$会出现在最终结果中。 根据上面的讨论可知，当$r$既没有出现在$S$也没有出现在$R$中时，插入$r$会导致$r$添加到最终的结果中。因此 $$(R \\cup \\Delta R) \\ominus S = (R \\ominus S) \\cup (\\Delta R \\ominus (R \\sqcup S))$$ 类似的，我们对$S$插入或删除的情况进行讨论，可得 $$ R \\ominus (S - \\nabla S) = (R \\ominus S) \\cup (\\nabla S \\sqcap (R \\ominus (S - \\nabla S)))$$ $$R \\ominus (S \\cup \\Delta S) = (R \\ominus S) - (\\Delta S \\sqcap (R \\ominus S))$$ 内连接 (Inner Join)我们用$R \\Join_p S$表示表$R$和表$S$按照连接条件$p$进行的连接操作。 内连接的变化传播方程如下 $$(R - \\nabla R) \\Join_p S = (R \\Join_p S) - (\\nabla R \\Join_p S)$$ $$(R \\cup \\Delta R) \\Join_p S = (R \\Join_p S) \\cup (\\Delta R \\Join_p S)$$ 左外连接 (Left Outer Join)我们使用$R ⟕_p S$表示表$R$和$S$按照条件$p$进行的左外连接操作。左外连接$R ⟕_p S$除了返回$R \\Join S$之外，还会将$R$中无法和$S$进行连接的记录用null补齐$S$中的字段返回。即 $$R ⟕_p S = (R \\Join_p S) \\cup ((R \\bar{\\ltimes} S) \\times {d_S})$$ 其中$d_S$ 是一个和$S$的字段一致并且所有列都为null的记录。 当$R$中某个记录$r$被删除时 如果在表$S$中存在$s$使得$p(r,s)$成立，那么$(r, s)$出现在原来的结果中，此时我们需要将$(r,s)$从最终的结果中删除。 如果在表$S$中不存在$s$使得$p(r,s)$成立，那么$(r, d_S)$ 出现在原来的结果中。此时我们需要将$(r, d_S)$从最终的结果中删除。 根据上面的讨论可知 $$(R - \\nabla R) ⟕_p S = (R ⟕_p S) - (\\nabla R ⟕_p S)$$ 当$R$中添加某个记录$r$时 如果在表$S$中存在$s$使得$p(r,s)$成立，那么$(r,s)$会出现在最终的结果中。 如果在表$S$中不存在$s$使得$p(r,s)$成立，那么$(r, d_S)$会出现在最终的结果中。 根据上面的讨论可知 $$(R \\cup \\Delta R) ⟕_p S = (R ⟕_p S) \\cup (\\Delta R ⟕_p S)$$ 类似的，我们对$S$插入或删除的情况进行讨论，可得 $$R ⟕_p (S - \\nabla S) = ((R ⟕_p S) - (R \\Join_p \\nabla S)) \\cup (((R \\ltimes_p \\nabla S) \\bar{\\ltimes}_p (S - \\nabla S)) \\times {d_S})$$ $$R ⟕_p (S \\cup \\Delta S) = ((R ⟕_p S) \\cup (R \\Join_p \\Delta S)) - (((R \\ltimes_p \\Delta S) \\bar{\\ltimes}_p S) \\times {d_S})$$ 全外连接 (Full Outer Join)我们使用$R ⟗_p S$表示表$R$和$S$按照条件$p$进行的全外连接操作。全外连接$R ⟗_p S$除了返回$R \\Join S$之外，还会将$R$中无法和$S$进行连接的记录用null补齐$S$中的字段返回，将$S$中无法和$R$进行连接的记录用null补齐$R$中的字段后返回。即 $$R ⟗_p S = (R \\Join_p S) \\cup ((R \\bar{\\ltimes} S) \\times {d_S}) \\cup ((S \\bar{\\ltimes} R) \\times {d_R})$$ 其中$d_S$ 是一个和$S$的字段一致并且所有列都为null的记录，$d_R$是一个和$R$的字段一致并且所有列都为null的记录。 和左外连接的情况类似，我们可得 $$(R - \\nabla R) ⟗_p S = ((R ⟗_p S) - (\\nabla R ⟕_p S)) \\cup (((S \\ltimes_p \\nabla R) \\bar{\\ltimes}_p (R - \\nabla R)) \\times {d_R})$$ $$(R \\cup \\Delta R) ⟗_p S = ((R ⟗_p S) \\cup (\\Delta R ⟕_p S)) - (((S \\ltimes_p \\Delta R) \\bar{\\ltimes}_p R) \\times {d_R})$$ 半连接 (Semi Join)我们使用$R \\ltimes_p S$表示表$R$和$S$按照条件$p$​进行的半连接操作。半连接$R \\ltimes_p S$返回$R$中和$S$可以按照连接条件$p$进行连接的记录，即 $$ R \\ltimes_p S = { r | r \\in R, \\exists s \\in S, p(r, s) }$$ 当$R$中某个记录$r$被删除时 如果在表$S$中存在$s$使得$p(r, s)$成立，那么$r$出现在原来的结果中。此时我们需要将$r$从最终的结果中删除。 如果在表$S$中不存在$s$使得$p(r, s)$成立，那么$r$没有出现在原来的结果中，因此也就不会对最终的结果产生影响。 根据上面的讨论可知 $$(R - \\nabla R) \\ltimes_p S = (R \\ltimes_p S) - (\\nabla R \\ltimes_p S)$$ 当$R$中添加某个记录$r$时 如果在表$S$中存在$s$使得$p(r, s)$成立，那么$r$会出现在最终的结果中。 如果在表$S$中不存在$s$使得$p(r, s)$成立，那么$r$不会出现在最终的结果中。 根据上面的讨论可知 $$(R \\cup \\Delta R) \\ltimes_p S = (R \\ltimes_p S) \\cup (\\Delta R \\ltimes_p S)$$ 类似的，我们对$S$插入或删除的情况进行讨论，可得 $$R \\ltimes_p (S - \\nabla S) = (R \\ltimes_p S) - ((R \\ltimes_p \\nabla S) \\bar{\\ltimes}_p (S - \\nabla S))$$ $$ R \\ltimes_p (S \\cup \\Delta S) = (R \\ltimes_p S) \\cup ((R \\ltimes_p \\Delta S) \\bar{\\ltimes}_p S))$$ 反半连接 (Anti Semi Join)我们使用$R \\bar{\\ltimes}_p S$表示表$R$和$S$按照条件$p$进行的反半连接操作。反半连接$R \\bar{\\ltimes}_p S$返回$R$中可以和$S$按照连接条件$p$进行连接的记录，即 $$ R \\bar{\\ltimes}_p S = { r | r \\in R, \\nexists s \\in S, p(r, s) }$$ 和半连接的情况类似，我们可得 $$(R - \\nabla R) \\bar{\\ltimes}_p S = (R \\bar{\\ltimes}_p S) - (\\nabla R \\bar{\\ltimes}_p S)$$ $$(R \\cup \\Delta R) \\bar{\\ltimes}_p S = (R \\bar{\\ltimes}_p S) \\cup (\\Delta R \\bar{\\ltimes}_p S)$$ $$R \\bar{\\ltimes}_p (S - \\nabla S) = (R \\bar{\\ltimes}_p S) \\cup ((R \\ltimes_p \\nabla S) \\bar{\\ltimes}_p (S - \\nabla S))$$ $$R \\bar{\\ltimes}_p (S \\cup \\Delta S) = (R \\bar{\\ltimes}_p S) - (R \\ltimes_p \\Delta S)$$ Related Work[1] S. Koenig et al. A transformational framework for the automatic control of derived data. In VLDB 1981, pp. 306-318. [2] O. Shmueli et al. Maintenance of views. In SIGMOD 1984, pp. 240-255. [3] J. Blakeley et al. Efficiently updating materialied views. In SIGMOD 1986, pp. 61-71. [4] X. Qian et al. Incremental recomputation of active relational expressions. In TKDE 1991 vol. 3(3) pp. 337-341. [5] T. Griffin et al. Incremental maintenance of views with duplicates. In SIGMOD 1995, pp. 328-339. [6] A. Gupta et al. Maintenance and self-maintenance of outerjoin views. In Next Generation Information Technology and Systems 1997. [7] T. Griffin et al. Algebraic change propagation for semijoin and outerjoin queries. In SIGMOD Record 1998 vol. 27(3), pp. 22-27. [8] H. Gupta et al. Incremental maintenance of aggregate and outerjoin expressions. In Information Systems 2006, vol. 31(6), pp. 435-464. [9] P. Larson et al. Efficient maintenance of materialized outer-join views. In ICDE 2007, pp. 56-65. [10] I. Mumick et al. Maintenance of data cubes and summary tables in a warehouse. In SIGMOD Record 1997, vol. 26(2), pp.100-111. [11] T. Palpanas et al. Incremental maintenance for non-distributive aggregate functions. In VLDB 2002, pp. 802-813. [12] T. Griffin et al. An improved algorithm for the incremental recomputation of active relational expressions. In TKDE 1997, vol. 9(3) pp. 508-511.","link":"/materialized-views/algebraic-methods/"},{"title":"Lossy Counting频数估计算法","text":"LossyCounting是R. Motwani和G. S. Manku在[1]中提出的另一个频数估计算法（该论文中的另一个算法为 Sticky Sampling算法）。虽然LossyCounting算法在Misra-Gries算法提出之后20年提出，但LossyCounting算法在估计误差上和Misra-Gries算法是一样的，在空间复杂度和计算复杂度上还不如Misra-Gries算法。 LossyCounting算法的对数据项的频数的估计可以满足$0 \\le f - \\hat{f} \\le \\epsilon n$，其中$f$为真实频数，$\\hat{f}$为估计频数，$n$为所有频数之和；所需的记录数为$\\frac{1}{\\epsilon}\\log(\\epsilon n)$。LossyCounting算法也可以对数据流中的频繁项进行估计，并对给定的阈值$s\\in(0,1)$满足 所有真实频数超过$sn$的数据项都能够被返回。 所有真实频数少于$(s-\\epsilon)n$的数据项都不会被返回。 算法实现LossyCounting算法将数据流划分成一个个窗口。每个窗口中包含了$\\lceil 1/\\epsilon \\rceil$个元素。每个窗口从1开始被编上号，当前窗口的编号即为$b_{current}$。如果当前已经处理的元素总数为$n$，则$b_{current}$的值为$\\left\\lfloor \\frac{n}{\\lceil 1/\\epsilon \\rceil} \\right\\rfloor \\le n\\epsilon$。 LossyCounting算法维护了一组记录$(e, f, \\Delta)$，其中$e$为数据流中的数据项，$f$为对$e$的频数的估计，而$\\Delta$则是$f$的最大可能的估计误差，也是这个元素在之前$b_{current}-1$个窗口中最多可能出现的次数。我们将这组记录记为$\\mathcal{S}$。 当一个新元素$e$到达时，我们首先检查$e$是否存在于$\\mathcal{S}$中。如果$e$已经存在于$\\mathcal{S}$中，那么我们直接将其对应的$f$加1。如果$e$没有在$\\mathcal{S}$中，那么我们在$\\mathcal{S}$中添加一个新记录$(e, 1, b_{current} - 1)$。每当我们处理完一个窗口后，我们就对$\\mathcal{S}$进行清理。对于一个记录$(e, f, \\Delta)$，如果$f + \\Delta \\le b_{current}$，那么我们就将其从$\\mathcal{S}$中删除。 当我们需要查询某个数据项$e$的频数时，如果$e$在$\\mathcal{S}$中，我们返回$f$作为其频数的估计；如果$e$不在$\\mathcal{S}$中，则返回0作为频数的估计。而当我们需要查询数据流中出现频数超过$sn$的数据项时，我们返回$\\mathcal{S}$中所有$f \\ge (s-\\epsilon)n$的数据项。 算法分析引理1. 当一个记录$(e, f, \\Delta)$被删除时，一定有$f_e \\le b_{current}$，其中$f_e$为$e$的真实频数。 证明. 我们通过归纳法证明。 当$b_{current}=1$时，即在第一个窗口时，所有记录的$f$都是和其对应真实频数相同，并且$\\Delta$都为0。如果某个记录$(e, f, \\Delta)$在第一个窗口结束时被删除，那么一定有$f_e \\le b_{current}$。 我们假设$b_{current} &lt; k$时，结论成立。 如果当$b_{current} = k$时，记录$(e, f, \\Delta)$被删除。注意到，我们在插入记录时会使用$b_{current}-1$作为$\\Delta$的值，并且在之后都不会修改$\\Delta$。因此记录$(e, f, \\Delta)$一定是在第$\\Delta + 1$个窗口中被插入到$\\mathcal{S}$中的。 而这个记录可能之前也存在于$\\mathcal{S}$中，并在某个窗口$r &lt; k$中从$\\mathcal{S}$中删除了。根据我们前面的归纳假设，当这个记录在窗口$r$中被删除时，有$f_e’ \\le r \\le \\Delta$，其中$f_e’$是数据项$e$在窗口r中被删除时的真实频数。 由于自从窗口$\\Delta +1$插入到$\\mathcal{S}$之后，$e$的每次出现都会记录到了对应的$f$中，因此有$f_e = f_e’ + f \\le \\Delta + f$。 注意到，我们在窗口$b_{current}$中只会删除$f + \\Delta \\le b_{current}$的记录，因此有$f_e \\le b_{current}$。 结论在$b_{currnet} = k$时也成立，命题得证。 定理1. 对于任意一个数据项$e$，LossyCounting算法对其频数的估计$\\hat{f}$满足 $$0 \\le f - \\hat{f} \\le \\epsilon n$$ 证明. 如果$e$不在$\\mathcal{S}$中，则$\\hat{f} = 0$。则其一定在之前某个窗口$b’ \\le b_{current}$中被删除。根据引理1可知 $$0 \\le f \\le b’ \\le b_{current} \\le \\epsilon n$$ 如果$e$在$\\mathcal{S}$中，并且$\\Delta = 0$，则说明$e$在第一个窗口就被添加到$\\mathcal{S}$中，$f = \\hat{f}$。 如果$e$在$\\mathcal{S}$中，并且$\\Delta \\ge 1$，则说明$e$在窗口$\\Delta +1$中被添加到$\\mathcal{S}$中。$e$可能在之前的某个窗口$b’$从$\\mathcal{S}$中被删除了。根据引理1可知，在删除时$e$的真实频数不超过$b’$，从而 $$0 \\le f - \\hat{f} \\le b’ \\le \\Delta \\le b_{current} \\le \\epsilon n$$ 综上，命题得证。 定理2. LossyCounting算法所保存的记录数最多为$\\frac{1}{\\epsilon}\\log(\\epsilon n)$。 证明. 令$B = b_{current}$为当前窗口的编号。对于$i \\in [1, B]$，令$d_i$表示$\\mathcal{S}$中在窗口$i$插入到$\\mathcal{S}$中的记录数目，即$\\Delta = i - 1$的记录数目。 由于我们在每个窗口结束时都会清理$\\mathcal{S}$中的记录。因此，对于$\\Delta = B-i$的记录，其数据项在窗口$B-i+1$到窗口$B$之间一定至少出现了$i$次；否则其就会在这期间从$\\mathcal{S}$中删除。 令$w = \\lceil 1/\\epsilon \\rceil$为每个窗口的大小，则我们有 $$\\sum_{i = 1}^j i \\cdot d_i \\le j \\cdot w, j = 1, 2, …, B$$ 我们根据归纳法来证明 $$\\sum_{i = 1}^j d_i \\le \\sum_{i = 1}^j \\frac{w}{i}, j = 1, 2, …, B$$ 当$j = 1$时，上式显然成立。 假设当$j &lt;k$时，上式成立。 由于$$\\begin{aligned}&amp; k\\sum_{i = 1}^k d_i \\\\=&amp; \\sum_{i = 1}^k i \\cdot d_i + \\sum_{i = 1}^1 d_i + \\sum_{i=1}^2 d_i + … + \\sum_{i = 1}^{k-1} d_i \\\\\\le &amp; kw + \\sum_{i=1}^{k-1} \\frac{(k-i)w}{i} \\\\=&amp; k\\sum_{i=1}^k \\frac{w}{i}\\end{aligned}$$因此，当$j = k$时，$\\sum_{i = 1}^j d_i \\le \\sum_{i = 1}^j \\frac{w}{i}$，结论成立。 由于$|\\mathcal{S}| = \\sum_{i = 1}^B d_i$，因此 $$|\\mathcal{S}| \\le \\sum_{i=1}^B \\frac{w}{i} \\le w \\log B \\le \\frac{1}{\\epsilon}\\log(\\epsilon n)$$ 参考文献[1] G. S. Manku, R. Motwani. Approximate Frequency Counts over Data Streams. In VLDB 2002, pp. 346-357.","link":"/sketches/lossy-counting/"},{"title":"Misra-Gries频数估计算法","text":"Misra-Gries算法最早由J. Misra和D. Gries在1982年提出 [1]。Misra-Gries算法可以看成是对Majority算法的一个扩展，可以对数据流中的频数提供相对误差为$\\epsilon$的估计，使用的空间复杂度为$\\mathrm{O}(1/\\epsilon)$。 到了2000年左右，随着对数据流研究的再次兴起，[2] 和 [3] 又重新提出了类似的算法来用于频数估计。和原始论文不同，[2] 使用了哈希表而非平衡搜索树来保证频繁项。[3] 则通过多个链表来提高清理记录时的效率，使其在最坏情况下仍然可以保证$O(1)$的开销。 原始论文侧重于频繁项的估计，并没有对频数估计的误差进行分析。[4] 证明了当$k = 1/\\epsilon$时，频数估计的相对误差为$\\epsilon$。[5] 则表明Misra-Gries算法的估计误差仅取决于那些长尾的数据项。考虑到真实环境中的数据分布通常是倾斜的（如zipf分布），这个结论可以进一步提高收紧了估计误差的边界。 [5] 进一步扩展了Misra-Gries算法，使其可以支持记录有不同权重的场景。[6] 则优化了权重更新场景下更新和合并的效率。[5] 还提供了Misra-Gries算法的合并操作，而 [7] 则对合并的空间复杂度提供了更强的边界。[7] 同时也证明了Misra-Gries算法本质上是和SpaceSaving算法等价的。 算法实现我们在Misra-Gries算法中维护了一组记录$(e, f)$，其中$e$是数据流中的数据项，$f$是对$e$的频数估计。我们将这组记录记为$\\mathcal{D}$。 Misra-Gries算法的更新算法如下所示。当一个新元素$i$到达时，我们首先检查其是否已经在$\\mathcal{D}$中存在。如果已经存在的话，那么我们直接将其对应的频数$f_i$加1；否则，我们在$\\mathcal{D}$中添加一个新记录$(e, 1)$。如果$\\mathcal{D}$中记录的数目超过了设定的阈值$k$，那么我们就需要对$\\mathcal{D}$进行清理。我们去除当前$\\mathcal{D}$中所有频数的最小值$f_m$，并将所有频数都减去$f_m$。如果一个数据项的频数变为$0$，那么我们就将其从$\\mathcal{D}$中删除。 Misra-Gries算法更新操作0if $i \\in \\mathcal{D}$, then 1 $f_i \\gets f_i + 1$ 2else 3​ $\\mathcal{D} \\gets \\mathcal{D} \\cup \\{i\\}$ 4​ $f_m = \\min \\{ f_e | e \\in \\mathcal{D} \\}$ 5​ for all $j \\in \\mathcal{D}$ 6​ $f_j \\gets f_j - f_m$ 7​ if $f_j = 0$, then 8​ $\\mathcal{D} \\gets \\mathcal{D} - \\{j \\}$ 9​ end if 10​ end for 11end if Misra-Gries算法的查询操作如下所示。当我们需要查询某个数据项的频数时，如果这个数据项存在于$\\mathcal{D}$中，我们就返回其在$\\mathcal{D}$中对应的频数；否则，我们直接返回$0$。 Misra-Gries算法查询操作0if $e \\in \\mathcal{D}$ 1​ return $f_e$ 2else 3​ return $0$ 4end if Misra-Gries算法也支持合并操作。在合并时，我们任意选择一个频繁集来作为基础，然后再将另一个频繁集中的记录逐个添加进去。Misra-Gries算法的合并操作如下所示： Misra-Gries算法合并操作0$\\mathcal{D} \\gets \\mathcal{D}_a$ 1for all $i \\in \\mathcal{D}_b$ 2​ if $i \\in \\mathcal{D}$, then 3​ $f_i \\gets f_i + f_{i, b}$ 4​ else 5​ $\\mathcal{D} \\gets \\mathcal{D} \\cup \\{i \\}$ 6​ $f_i \\gets f_{i, b}$ 7​ end if 8​ if $|\\mathcal{D}| &gt; k$, then 9​ $f_m \\gets \\min \\{ f_e | e \\in \\mathcal{D} \\}$ 10​ for all $j \\in \\mathcal{D}$ 11​ $f_j \\gets f_j - f_m$ 12​ if $f_j = 0$, then 13​ $\\mathcal{D} \\gets \\mathcal{D} - \\{j\\}$ 14​ end if 15​ end for 16​ end if 17end for 算法分析定理. Misra-Gries算法对真实频数$f$提供的估计$\\hat{f}$满足 $$ 0 \\le f - \\hat{f} \\le \\epsilon n $$ 其中$n$为所有数据项的频数之和。此时所需的空间复杂度为$\\mathrm{O}(1/\\epsilon)$。 证明. 令$n$为数据流中已经出现的记录数目，$n’$为保存在$\\mathcal{D}$中所有频数的和。 我们对于频数估计的误差来自于我们对$\\mathcal{D}$的清理操作。每次清理时，我们会将$\\mathcal{D}$中的记录都减去一个相同的值。因此在整个计算过程中，受到影响的数据项数目一定大于等于$k$。因此，我们有 $$ 0 \\le f - \\hat{f} \\le \\frac{n - n’}{k} \\le \\frac{n}{k} $$ 令$k = 1/\\epsilon$，则 $$0 \\le f - \\hat{f} \\le \\epsilon n$$ 参考文献[1] J. Misra, D. Gries. Finding repeated elements. In Science of Computer Programming 1982, vol. 2(2), pp. 143-152. [2] E. Demaine et al. Frequency estimation of internet packet streams with limited space. In ESA 2002, pp. 348-360. [3] R. Karp et al. A simple algorithm for finding frequent elements in streams and bags. In TODS 2003, vol. 28(1), pp. 51-55. [4] P. Bose et al. Bounds for frequency estimation of packet streams. In SIROCCO 2003. [5] R. Berinde et al. Space-optimal heavy hitters with strong error bounds. In PODS 2009, pp. 157-166. [6] D. Anderson et al. A high-performance algorithm for identifying frequent items in data streams. In IMC 2017, pp. 268-282. [7] P. Agarwal et al. Mergeable summaries. In PODS 2012, pp. 23-34.","link":"/sketches/misra-gries/"},{"title":"Morris频数估计算法","text":"MorrisCounter算法是R. Morris于1978年提出的一种用于估计频数的算法 [1]. 当时Morris需要编写一段代码来对大量事件进行计数，但是他能使用的只有一个8位的计数器。为了能在有限的存储空间内完成任务，他发明了MorrisCounter算法，能够使用 $ O(\\log \\log N + \\log 1/ \\epsilon + \\log 1 / \\delta ) $个比特，对频数进行估计，并且保证估计频数$\\hat{f}$和真实频数$f$之间满足： $$ Pr[|\\hat{f} - f| \\le \\epsilon f] \\ge 1 - \\delta $$ 算法实现对计数进行估计的一个简单思想就是，我们不必严格记录下每次看到的新事件。我们可以以一定的概率记录新事件。每当我们看到一个新事件，我们就抛一枚硬币。如果正面朝上，我们就增加计数；否则我们就忽略它。这种基于多次抛硬币的结果可以通过一个二项式分布来描述。通过二项式分布的标准偏差，我们就可以对估计误差进行分析。 这种抛硬币的方式虽然可以减少计数时所需的空间，但其所需的空间仍然和计数呈线性关系。为了能够进一步获得更好的空间复杂度，MorrisCounter算法对抛硬币的概率进行动态调整，随着计数的增加而逐步降低硬币朝上的概率：当第一次看到事件时，更新的频率为1，下一次为1/2，然后为1/4，以此类推。 在MorrisCounter的实现中，我们使用$c$来保存对当前计数的估计，并使用参数$b \\in (1, 2]$来作为是否计数的参数。 MorrisCounter的更新操作实现如下 MorrisCounter更新操作0randomly pick $y$ from $[0, 1]$ 1if $y &lt; b^{-c}$, then 2$~~~~c \\gets c + 1$ 3end if MorrisCounter的查询操作实现如下 MorrisCounter查询操作0return $(b^c - 1)/(b-1)$ 如果两个MorrisCounter的参数$b$是相同的，那么我们也可以将这两个MorrisCounter进行合并。当合并时，我们选择较大的计数值作为基础，将较小的计数值按照更新操作的方式累加到结果上。 MorrisCounter查询操作0$\\alpha = \\min(c_a, c_b)$, $\\beta = \\min(c_a, c_b)$ 1for $j$ in $[0, \\alpha]$ 2$~~~~$ randomly pick $y$ from $[0, 1] 3$~~~~$ if $y &lt; b^{j-\\beta}$ 4$~~~~~~~~$ $\\beta \\gets \\beta + 1$ 5$~~~~$ end if 6end for 7return $\\beta$ 算法分析令$C_n$表示经过$n$次更新操作之后$c$的值，$X_n = (b^{C_n} - 1)/(b-1)$为经过$n$次更新操作之后对真实频数的估计值。 引理1$$E[X_n] = n$$证明.$$\\begin{aligned}E[X_n] &amp;= \\sum_c Pr[C_n = c] \\frac{b^c - 1}{b - 1} \\\\&amp;= \\sum_c (Pr[C_n = c - 1]b^c + Pr[C_{n-1} = c](1 - b^{-c}))\\frac{b^c - 1}{b - 1} \\\\&amp;= \\sum_c Pr[C_{n-1} = c] \\left( b^{-c} \\frac{b^{c+1} - 1}{b-1} + (1 - b^{-c})\\frac{b^c-1}{b-1}\\right) \\\\&amp;= \\sum_c Pr[C_{n-1} = c] \\frac{b^c-1}{b-1} + 1 \\\\&amp;= E[X_{n-1}] + 1\\end{aligned}$$ 引理2.$$ var[X_n] \\le \\frac{b-1}{2} n^2$$ 证明. 令$Y_n = X_n + \\frac{1}{b-1}$，则$$\\begin{aligned}E[Y_n^2] &amp;= \\sum_c Pr[C_n = c]\\left(\\frac{b^c}{b-1}\\right)^2 \\\\&amp;= \\sum_c Pr[C_{n-1} = c] \\left( b^{-c}\\left(\\frac{b^{c+1}}{b-1}\\right)^2 + (1-b^{-c})\\left(\\frac{b^c}{b-1}\\right)^2 \\right) \\\\&amp;= \\sum_c Pr[C_{n-1} = c] \\left( \\left(\\frac{b^c}{b-1}\\right)^2 + \\frac{b^{-c}}{(b-1)^2} \\left(\\left(b^{c+1}\\right)^2 - \\left(b^c\\right)^2 \\right) \\right) \\\\&amp;= E[Y_{n-1}^2] + \\sum_c Pr[C_{n-1} = c] \\frac{b^{-c}}{(b-1)^2}(b^{c+1}-b^c)(b^{c+1}+b^c) \\\\&amp;= E[Y_{n-1}^2] + (b+1) \\sum_c Pr[C_{n-1} = c] \\frac{b^c}{b-1} \\\\&amp;= E[Y_{n-1}^2] + (b+1) E[Y_{n-1}] \\\\&amp;= E[Y_{n-1}^2] + (b+1)(n-1) \\\\&amp;= E[Y_0^2] + (b+1)\\sum_{i=0}^{n-1} i\\end{aligned}$$由于$Y_0 = \\frac{1}{b-1}$，因此$$E[X_n^2]=E\\left[\\left(Y_n - \\frac{1}{b-1}\\right)^2 \\right] \\le E[Y_n^2 - Y_0^2] = \\frac{b+1}{2}n(n-1)$$ 从而$$var[X_n] \\le E[X_n^2] - E[X_n]^2 = \\frac{b-1}{2}n^2$$ 定理. MorrisCounter对真实频数$n$的近似估计$X_n$满足 $$Pr[|X_n - n| \\le \\epsilon n] \\ge 1 - \\delta$$ 此时所需的空间复杂度为$\\mathrm{O}\\left(\\log \\frac{1}{\\epsilon} + \\log \\frac{1}{\\delta} + \\log\\log\\epsilon^2\\delta n \\right)$。 证明. 根据引理1和引理2，由Chebyshev不等式可得$$Pr[|X_n - n| \\ge \\epsilon n] \\le \\frac{b-1}{2}n^2/\\epsilon^2n^2 = \\frac{b-1}{2}\\epsilon^2$$ 令$b \\le 1 + 2\\epsilon^2\\delta$，那么我们就可以以至少$1-\\delta$的概率提供对频数相对误差为$\\epsilon$的估计。 此时MorisCounter算法所需的空间复杂度为$\\mathrm{O}\\left(\\log \\frac{1}{\\epsilon} + \\log \\frac{1}{\\delta} + \\log\\log\\epsilon^2\\delta n \\right)$。 参考文献 [1] R. Morris. Counting large numbers of events in small registers. In Communications of the ACM, vol 21, issue 10, pp. 840-842, 1978.","link":"/sketches/morris-counter/"},{"title":"Sticky Sampling频数估计算法","text":"StickySampling是R. Motwani和G. S. Manku在2002年提出的一种基于采样的频繁项估计算法 [1]。在原始论文中，作者号称它能够对数据项的频数以超过$1-\\delta$的概率提供相对误差为$\\epsilon$的估计，并返回数据流中所有频率超过给阈值的所有数据项，其所需的空间复杂度为$\\mathrm{O} \\left( \\log \\frac{1}{\\epsilon \\delta} \\right)$。但这个结论的证明可能存在问题。 算法实现在StickySampling算法中，我们维护了一组记录$(e, f)$，其中$e$为数据流中的数据项，而$f$是对$e$频数的估计。我们将这组记录记为$\\mathcal{S}$。 每当有一个新元素$e$到达时，如果其已经存在于$\\mathcal{S}$中，我们将其对应的频数$f_e$增加1；否则我们以采样率$1/r$对元素进行采样。如果$e$被采样，我们就在$\\mathcal{S}$中插入一个新记录$(e, 1)$。和MorrisCounter算法类似，StickySampling也对采样率进行动态调整。最开始的$2t$个元素，采样率为1；而对之后的$2t$个元素，$r$被设置为2，即以采样率$1/2$进行采样；再之后的$4t$个元素的采样率为$1/4$，以此类推。在这里，$t$是一个由误差概率$\\delta$和$\\epsilon$决定的一个参数。 每当采样率进行调整的时候，我们也会扫描$\\mathcal{S}$中的元素进行清理。对于每个$\\mathcal{S}$中的记录$(e, f)$，我们投掷一个无偏的硬币。如果硬币反面朝上时，我们就将这个记录的频数$f$减1。如果$f$变为0，那么就将这个记录从$\\mathcal{S}$中删除。我们重复这个投掷过程直到硬币正面朝上。在原始论文中，只提到了投掷使用的硬币是无偏的，而没有对反面朝上的概率进行明确。从后续的证明来看，硬币反面朝上的概率应为$(1-1/r)$。 当用户需要查询数据流中出现频率超过$s$的数据项时，我们就输出$\\mathcal{S}$中$f \\ge (s - \\epsilon) N$的数据项即可。 算法分析下面是原始论文中的证明。 我们按照采样率对数据流划分成一组窗口。第一个窗口包含$2t$个元素，而之后的窗口中都包含了$rt$个元素。假设我们当前窗口的采样率为$1/r$，那么之前窗口中的元素总数为$2t + 2t + 4t + … + (r/2)t = rt$。我们用$N$表示当前已经处理的元素总数，则$N = rt + rt’\\ge rt$，其中$t’ \\in [0, 1)$。从而$1/r \\ge t/N$。 对于一次衰减操作，我们减去的频数和连续投掷硬币为反面的次数一样，因此这个值服从几何分布，其超过$\\epsilon N$的概率不超过$(1 - 1/r)^{\\epsilon N}$。由于$1/r \\ge t/N$，则这个衰减值超过$\\epsilon N$的概率不超过$(1 - t/N)^{\\epsilon N}$，进而不超过$e^{-\\epsilon t}$。 在整个数据流中，频数至少为$sN(s \\in [0, 1])$的数据项最多只有$1/s$个。这些数据项中任意一个减少的频数超过$\\epsilon N$的概率最多只有$e^{-\\epsilon t}/s$。令$t \\ge \\frac{1}{\\epsilon}\\log \\left( \\frac{1}{s \\delta} \\right)$，则这些数据项有有任意一个减少的频数超过$\\epsilon N$的概率不超过$\\delta$。 在上面的证明过程中，存在以下问题 对于频数估计的误差，来自于两个方面。一个是当数据项还未在$\\mathcal{S}$由于采样导致的频数减少；以及在每次调整采样率时的衰减操作。但上面的证明过程并没有分别考虑这两方面的影响。 一个数据项可能经历多次衰减操作，并且在每次衰减操作时，$r$和$N$的值是不同的。但上面的证明过程并没有考虑多次衰减的影响。 参考文献[1] G. S. Manku, R. Motwani. Approximate Frequency Counts over Data Streams. In VLDB 2002, pp. 346-357.","link":"/sketches/sticky-sampling/"}],"tags":[{"name":"数据湖仓","slug":"数据湖仓","link":"/tags/%E6%95%B0%E6%8D%AE%E6%B9%96%E4%BB%93/"},{"name":"ETL","slug":"ETL","link":"/tags/ETL/"},{"name":"物化视图","slug":"物化视图","link":"/tags/%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/"},{"name":"数据流","slug":"数据流","link":"/tags/%E6%95%B0%E6%8D%AE%E6%B5%81/"},{"name":"概要算法","slug":"概要算法","link":"/tags/%E6%A6%82%E8%A6%81%E7%AE%97%E6%B3%95/"},{"name":"频数估计","slug":"频数估计","link":"/tags/%E9%A2%91%E6%95%B0%E4%BC%B0%E8%AE%A1/"}],"categories":[{"name":"数据湖仓","slug":"数据湖仓","link":"/categories/%E6%95%B0%E6%8D%AE%E6%B9%96%E4%BB%93/"},{"name":"物化视图","slug":"物化视图","link":"/categories/%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/"},{"name":"概要算法","slug":"概要算法","link":"/categories/%E6%A6%82%E8%A6%81%E7%AE%97%E6%B3%95/"},{"name":"维护方法","slug":"物化视图/维护方法","link":"/categories/%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/%E7%BB%B4%E6%8A%A4%E6%96%B9%E6%B3%95/"},{"name":"频数估计","slug":"概要算法/频数估计","link":"/categories/%E6%A6%82%E8%A6%81%E7%AE%97%E6%B3%95/%E9%A2%91%E6%95%B0%E4%BC%B0%E8%AE%A1/"}],"pages":[{"title":"About","text":"I’m Xiaogang Shi, currently the head of the computing team at Kwaishou. Before that, I used to work as the head of the computing team at Tencent. I obtained PhD from Peking University 2016, advised by Prof. Bin Cui. I worked with Prof. Beng Chin OOI as a visiting scholar at NUS in 2013. I have served in the technical program committee of various international conferences, including KDD, SDM, DASFAA and BigData. I am also a committer of the Apache Flink project. Research InterestsDistributed and Parallel Computing, Databases, Query Optimization, Access Methods, Graph Processing, Stream Processing Publications Xiaogang Shi, Bin Cui, Gill Dobbie, Beng Chin Ooi. A unified ad-hoc data processing system. In ACM Transaction on Database Systems (TODS), vol. 42, issue 1, no. 6. Xiaogang Shi, Bin Cui, Yingxia Shao, Yunhai Tong. Tornado: A system for real-time iterative Analysis over evolving data. In Proceedings of the 2016 ACM SIGMOD International Conference on Management of Data (SIGMOD 2016), pp. 417-430. Xiaogang Shi, Bin Cui, Gill Dobbie, Beng Chin Ooi. Towards unified ad-hoc data processing. In Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data (SIGMOD 2014), pp. 1263-1274. Xiaogang Shi, Yanfei Lv, Yingxia Shao, Bin Cui. bCATE: A balanced contention-aware transaction execution model for highly concurrent OLTP systems. In the 14th International Conference on Web-Age Information Management (WAIM 2013), pp. 769-780.","link":"/about/index.html"}]}